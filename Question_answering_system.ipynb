{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvC0h_T3R9g8"
      },
      "source": [
        "# Question answer on Squad (Stanford question answer dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXLmA1sVSk1g",
        "outputId": "ac5792d3-8317-4bad-8582-b4f557f5ac0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKa0AjNzryo7",
        "outputId": "f3d6f7cb-32c4-4eaf-b247-25db2d31c600"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"squad\")\n",
        "total_examples = len(raw_datasets[\"train\"])\n",
        "percentage_to_keep = 0.05\n",
        "num_examples_to_keep = int(total_examples * percentage_to_keep)\n",
        "raw_datasets[\"train\"] = raw_datasets[\"train\"].select(range(num_examples_to_keep))\n",
        "raw_datasets[\"validation\"] = raw_datasets[\"validation\"].select(range(num_examples_to_keep))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_ZyqqmSScr6",
        "outputId": "03ebb875-96d7-4c30-91fb-48ba6de36fea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '5733be284776f41900661182',\n",
              " 'title': 'University_of_Notre_Dame',\n",
              " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
              " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
              " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_datasets['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K7RftIMSzgK",
        "outputId": "4744519b-7922-4315-ca15-75bc105f0ce6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "    num_rows: 0\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_datasets[\"train\"].filter(lambda x: len(x[\"answers\"][\"text\"]) != 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgroVJBeUXrQ",
        "outputId": "21904e83-2f32-4203-be88-380394471f04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '56be4db0acb8001400a502ee',\n",
              " 'title': 'Super_Bowl_50',\n",
              " 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
              " 'question': 'Where did Super Bowl 50 take place?',\n",
              " 'answers': {'text': ['Santa Clara, California',\n",
              "   \"Levi's Stadium\",\n",
              "   \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"],\n",
              "  'answer_start': [403, 355, 355]}}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_datasets[\"validation\"][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_khBSumUjYq"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"distilbert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "WVcDfsLFV9G4",
        "outputId": "7def9d6f-ec33-4308-c61b-dba098aa0fff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context = raw_datasets[\"train\"][1][\"context\"]\n",
        "question = raw_datasets[\"train\"][1][\"question\"]\n",
        "\n",
        "inputs = tokenizer(question, context)\n",
        "tokenizer.decode(inputs['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGLOFFyhaW1h"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(\n",
        "    question,\n",
        "    context,\n",
        "    max_length=100,\n",
        "    truncation=\"only_second\",\n",
        "    stride=50,\n",
        "    return_overflowing_tokens=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qafhpsbxa7m4",
        "outputId": "bdfc98dc-f6f9-4d33-d31b-8a98e5158dcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the G [SEP]\n",
            "[CLS] What is in front of the Notre Dame Main Building? [SEP] facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernade [SEP]\n",
            "[CLS] What is in front of the Notre Dame Main Building? [SEP] of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern [SEP]\n",
            "[CLS] What is in front of the Notre Dame Main Building? [SEP]rdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n"
          ]
        }
      ],
      "source": [
        "for ids in inputs[\"input_ids\"]:\n",
        "  print(tokenizer.decode(ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dc-9ajEbI58",
        "outputId": "1021fafe-a5ca-45e8-ef87-43159e01c7dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'overflow_to_sample_mapping'])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZaCIeMybsmq",
        "outputId": "aaa625cf-5d41-42fc-abee-f6b71ebcabd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 0, 0, 0]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs['overflow_to_sample_mapping']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO3BQ5o1b1SR"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(\n",
        "    raw_datasets[\"train\"][:3][\"question\"],\n",
        "    raw_datasets['train'][:3][\"context\"],\n",
        "    max_length=100,\n",
        "    truncation=\"only_second\",\n",
        "    stride=50,\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEyoVvXlcUnq",
        "outputId": "acd2d540-4297-4c6a-8f5e-75a32f1fe0bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs['overflow_to_sample_mapping']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpPVclDHcY0_",
        "outputId": "c766cba6-5223-4312-e83f-8fa64d412dcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basi [SEP]\n",
            "[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin [SEP]\n",
            "[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 [SEP]\n",
            "[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP]. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n",
            "[CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the G [SEP]\n",
            "[CLS] What is in front of the Notre Dame Main Building? [SEP] facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernade [SEP]\n",
            "[CLS] What is in front of the Notre Dame Main Building? [SEP] of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern [SEP]\n",
            "[CLS] What is in front of the Notre Dame Main Building? [SEP]rdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n",
            "[CLS] The Basilica of the Sacred heart at Notre Dame is beside to which structure? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basi [SEP]\n",
            "[CLS] The Basilica of the Sacred heart at Notre Dame is beside to which structure? [SEP] the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin [SEP]\n",
            "[CLS] The Basilica of the Sacred heart at Notre Dame is beside to which structure? [SEP] Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 [SEP]\n",
            "[CLS] The Basilica of the Sacred heart at Notre Dame is beside to which structure? [SEP]. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n"
          ]
        }
      ],
      "source": [
        "for ids in inputs[\"input_ids\"]:\n",
        "  print(tokenizer.decode(ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLjgXVz6cmVu"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(\n",
        "    question,\n",
        "    context,\n",
        "    max_length=100,\n",
        "    truncation=\"only_second\",\n",
        "    stride=50,\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xPDKZc9duIc",
        "outputId": "1c0f4a0d-6e5a-465b-bd1e-16586b7a66b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsbWc93Hdx7J",
        "outputId": "907088e2-1fc1-4c71-c088-e48fe5b3e526"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[(0, 0),\n",
              "  (0, 4),\n",
              "  (5, 7),\n",
              "  (8, 10),\n",
              "  (11, 16),\n",
              "  (17, 19),\n",
              "  (20, 23),\n",
              "  (24, 29),\n",
              "  (30, 34),\n",
              "  (35, 39),\n",
              "  (40, 48),\n",
              "  (48, 49),\n",
              "  (0, 0),\n",
              "  (0, 13),\n",
              "  (13, 15),\n",
              "  (15, 16),\n",
              "  (17, 20),\n",
              "  (21, 27),\n",
              "  (28, 31),\n",
              "  (32, 33),\n",
              "  (34, 42),\n",
              "  (43, 52),\n",
              "  (52, 53),\n",
              "  (54, 56),\n",
              "  (56, 58),\n",
              "  (59, 62),\n",
              "  (63, 67),\n",
              "  (68, 76),\n",
              "  (76, 77),\n",
              "  (77, 78),\n",
              "  (79, 83),\n",
              "  (84, 88),\n",
              "  (89, 91),\n",
              "  (92, 93),\n",
              "  (94, 100),\n",
              "  (101, 107),\n",
              "  (108, 110),\n",
              "  (111, 114),\n",
              "  (115, 121),\n",
              "  (122, 126),\n",
              "  (126, 127),\n",
              "  (128, 139),\n",
              "  (140, 142),\n",
              "  (143, 148),\n",
              "  (149, 151),\n",
              "  (152, 155),\n",
              "  (156, 160),\n",
              "  (161, 169),\n",
              "  (170, 173),\n",
              "  (174, 180),\n",
              "  (181, 183),\n",
              "  (183, 184),\n",
              "  (185, 187),\n",
              "  (188, 189),\n",
              "  (190, 196),\n",
              "  (197, 203),\n",
              "  (204, 206),\n",
              "  (207, 213),\n",
              "  (214, 218),\n",
              "  (219, 223),\n",
              "  (224, 226),\n",
              "  (226, 229),\n",
              "  (229, 232),\n",
              "  (233, 237),\n",
              "  (238, 241),\n",
              "  (242, 248),\n",
              "  (249, 250),\n",
              "  (250, 251),\n",
              "  (251, 254),\n",
              "  (254, 256),\n",
              "  (257, 259),\n",
              "  (260, 262),\n",
              "  (263, 264),\n",
              "  (264, 265),\n",
              "  (265, 268),\n",
              "  (268, 269),\n",
              "  (269, 270),\n",
              "  (271, 275),\n",
              "  (276, 278),\n",
              "  (279, 282),\n",
              "  (283, 287),\n",
              "  (288, 296),\n",
              "  (297, 299),\n",
              "  (300, 303),\n",
              "  (304, 312),\n",
              "  (313, 315),\n",
              "  (316, 319),\n",
              "  (320, 326),\n",
              "  (327, 332),\n",
              "  (332, 333),\n",
              "  (334, 345),\n",
              "  (346, 352),\n",
              "  (353, 356),\n",
              "  (357, 358),\n",
              "  (358, 361),\n",
              "  (361, 365),\n",
              "  (366, 368),\n",
              "  (369, 372),\n",
              "  (373, 374),\n",
              "  (0, 0)],\n",
              " [(0, 0),\n",
              "  (0, 4),\n",
              "  (5, 7),\n",
              "  (8, 10),\n",
              "  (11, 16),\n",
              "  (17, 19),\n",
              "  (20, 23),\n",
              "  (24, 29),\n",
              "  (30, 34),\n",
              "  (35, 39),\n",
              "  (40, 48),\n",
              "  (48, 49),\n",
              "  (0, 0),\n",
              "  (174, 180),\n",
              "  (181, 183),\n",
              "  (183, 184),\n",
              "  (185, 187),\n",
              "  (188, 189),\n",
              "  (190, 196),\n",
              "  (197, 203),\n",
              "  (204, 206),\n",
              "  (207, 213),\n",
              "  (214, 218),\n",
              "  (219, 223),\n",
              "  (224, 226),\n",
              "  (226, 229),\n",
              "  (229, 232),\n",
              "  (233, 237),\n",
              "  (238, 241),\n",
              "  (242, 248),\n",
              "  (249, 250),\n",
              "  (250, 251),\n",
              "  (251, 254),\n",
              "  (254, 256),\n",
              "  (257, 259),\n",
              "  (260, 262),\n",
              "  (263, 264),\n",
              "  (264, 265),\n",
              "  (265, 268),\n",
              "  (268, 269),\n",
              "  (269, 270),\n",
              "  (271, 275),\n",
              "  (276, 278),\n",
              "  (279, 282),\n",
              "  (283, 287),\n",
              "  (288, 296),\n",
              "  (297, 299),\n",
              "  (300, 303),\n",
              "  (304, 312),\n",
              "  (313, 315),\n",
              "  (316, 319),\n",
              "  (320, 326),\n",
              "  (327, 332),\n",
              "  (332, 333),\n",
              "  (334, 345),\n",
              "  (346, 352),\n",
              "  (353, 356),\n",
              "  (357, 358),\n",
              "  (358, 361),\n",
              "  (361, 365),\n",
              "  (366, 368),\n",
              "  (369, 372),\n",
              "  (373, 374),\n",
              "  (374, 377),\n",
              "  (377, 379),\n",
              "  (379, 380),\n",
              "  (381, 382),\n",
              "  (383, 389),\n",
              "  (390, 395),\n",
              "  (396, 398),\n",
              "  (399, 405),\n",
              "  (406, 409),\n",
              "  (410, 420),\n",
              "  (420, 421),\n",
              "  (422, 424),\n",
              "  (425, 427),\n",
              "  (428, 429),\n",
              "  (430, 437),\n",
              "  (438, 440),\n",
              "  (441, 444),\n",
              "  (445, 446),\n",
              "  (446, 449),\n",
              "  (449, 451),\n",
              "  (452, 454),\n",
              "  (455, 458),\n",
              "  (458, 462),\n",
              "  (462, 463),\n",
              "  (464, 470),\n",
              "  (471, 476),\n",
              "  (477, 480),\n",
              "  (481, 487),\n",
              "  (488, 492),\n",
              "  (493, 500),\n",
              "  (500, 502),\n",
              "  (503, 511),\n",
              "  (512, 514),\n",
              "  (515, 520),\n",
              "  (521, 525),\n",
              "  (525, 528),\n",
              "  (0, 0)],\n",
              " [(0, 0),\n",
              "  (0, 4),\n",
              "  (5, 7),\n",
              "  (8, 10),\n",
              "  (11, 16),\n",
              "  (17, 19),\n",
              "  (20, 23),\n",
              "  (24, 29),\n",
              "  (30, 34),\n",
              "  (35, 39),\n",
              "  (40, 48),\n",
              "  (48, 49),\n",
              "  (0, 0),\n",
              "  (313, 315),\n",
              "  (316, 319),\n",
              "  (320, 326),\n",
              "  (327, 332),\n",
              "  (332, 333),\n",
              "  (334, 345),\n",
              "  (346, 352),\n",
              "  (353, 356),\n",
              "  (357, 358),\n",
              "  (358, 361),\n",
              "  (361, 365),\n",
              "  (366, 368),\n",
              "  (369, 372),\n",
              "  (373, 374),\n",
              "  (374, 377),\n",
              "  (377, 379),\n",
              "  (379, 380),\n",
              "  (381, 382),\n",
              "  (383, 389),\n",
              "  (390, 395),\n",
              "  (396, 398),\n",
              "  (399, 405),\n",
              "  (406, 409),\n",
              "  (410, 420),\n",
              "  (420, 421),\n",
              "  (422, 424),\n",
              "  (425, 427),\n",
              "  (428, 429),\n",
              "  (430, 437),\n",
              "  (438, 440),\n",
              "  (441, 444),\n",
              "  (445, 446),\n",
              "  (446, 449),\n",
              "  (449, 451),\n",
              "  (452, 454),\n",
              "  (455, 458),\n",
              "  (458, 462),\n",
              "  (462, 463),\n",
              "  (464, 470),\n",
              "  (471, 476),\n",
              "  (477, 480),\n",
              "  (481, 487),\n",
              "  (488, 492),\n",
              "  (493, 500),\n",
              "  (500, 502),\n",
              "  (503, 511),\n",
              "  (512, 514),\n",
              "  (515, 520),\n",
              "  (521, 525),\n",
              "  (525, 528),\n",
              "  (528, 531),\n",
              "  (532, 534),\n",
              "  (534, 537),\n",
              "  (537, 541),\n",
              "  (542, 544),\n",
              "  (545, 549),\n",
              "  (549, 550),\n",
              "  (551, 553),\n",
              "  (554, 557),\n",
              "  (558, 561),\n",
              "  (562, 564),\n",
              "  (565, 568),\n",
              "  (569, 573),\n",
              "  (574, 579),\n",
              "  (580, 581),\n",
              "  (581, 584),\n",
              "  (585, 587),\n",
              "  (588, 589),\n",
              "  (590, 596),\n",
              "  (597, 601),\n",
              "  (602, 606),\n",
              "  (607, 615),\n",
              "  (616, 623),\n",
              "  (624, 625),\n",
              "  (626, 633),\n",
              "  (634, 637),\n",
              "  (638, 641),\n",
              "  (642, 646),\n",
              "  (647, 651),\n",
              "  (651, 652),\n",
              "  (652, 653),\n",
              "  (654, 656),\n",
              "  (657, 658),\n",
              "  (659, 665),\n",
              "  (665, 666),\n",
              "  (667, 673),\n",
              "  (0, 0)],\n",
              " [(0, 0),\n",
              "  (0, 4),\n",
              "  (5, 7),\n",
              "  (8, 10),\n",
              "  (11, 16),\n",
              "  (17, 19),\n",
              "  (20, 23),\n",
              "  (24, 29),\n",
              "  (30, 34),\n",
              "  (35, 39),\n",
              "  (40, 48),\n",
              "  (48, 49),\n",
              "  (0, 0),\n",
              "  (458, 462),\n",
              "  (462, 463),\n",
              "  (464, 470),\n",
              "  (471, 476),\n",
              "  (477, 480),\n",
              "  (481, 487),\n",
              "  (488, 492),\n",
              "  (493, 500),\n",
              "  (500, 502),\n",
              "  (503, 511),\n",
              "  (512, 514),\n",
              "  (515, 520),\n",
              "  (521, 525),\n",
              "  (525, 528),\n",
              "  (528, 531),\n",
              "  (532, 534),\n",
              "  (534, 537),\n",
              "  (537, 541),\n",
              "  (542, 544),\n",
              "  (545, 549),\n",
              "  (549, 550),\n",
              "  (551, 553),\n",
              "  (554, 557),\n",
              "  (558, 561),\n",
              "  (562, 564),\n",
              "  (565, 568),\n",
              "  (569, 573),\n",
              "  (574, 579),\n",
              "  (580, 581),\n",
              "  (581, 584),\n",
              "  (585, 587),\n",
              "  (588, 589),\n",
              "  (590, 596),\n",
              "  (597, 601),\n",
              "  (602, 606),\n",
              "  (607, 615),\n",
              "  (616, 623),\n",
              "  (624, 625),\n",
              "  (626, 633),\n",
              "  (634, 637),\n",
              "  (638, 641),\n",
              "  (642, 646),\n",
              "  (647, 651),\n",
              "  (651, 652),\n",
              "  (652, 653),\n",
              "  (654, 656),\n",
              "  (657, 658),\n",
              "  (659, 665),\n",
              "  (665, 666),\n",
              "  (667, 673),\n",
              "  (674, 679),\n",
              "  (680, 686),\n",
              "  (687, 689),\n",
              "  (690, 694),\n",
              "  (694, 695),\n",
              "  (0, 0)]]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs['offset_mapping']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDQvRLo2d6OZ",
        "outputId": "3719fcf7-16f3-48fd-bf85-66bf852a4676"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(inputs['offset_mapping'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQbWHpCUh0t3",
        "outputId": "62a20376-5a59-4c60-af91-49d4b913ce5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[None,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " None,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " None]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs.sequence_ids(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zyk9g_2gsVGo",
        "outputId": "8ac4e244-2cc6-4038-bb2e-15e6f594ddbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13, 98)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence_ids = inputs.sequence_ids(0)\n",
        "ctx_start = sequence_ids.index(1)\n",
        "ctx_end = len(sequence_ids) - sequence_ids[::-1].index(1) -1\n",
        "ctx_start, ctx_end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtkPsvXjtYNt"
      },
      "outputs": [],
      "source": [
        "answer = raw_datasets[\"train\"][1]['answers']\n",
        "ans_start_char = answer['answer_start'][0]\n",
        "ans_end_char = ans_start_char + len(answer['text'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2adal3Lt27I"
      },
      "outputs": [],
      "source": [
        "def find_answer_token_idx(\n",
        "    ctx_start,\n",
        "    ctx_end,\n",
        "    ans_start_char,\n",
        "    ans_end_char,\n",
        "    offset):\n",
        "\n",
        "    start_idx = 0\n",
        "    end_idx = 0\n",
        "    if(offset[ctx_start][0] > ans_start_char or offset[ctx_end][1] < ans_end_char):\n",
        "        pass\n",
        "    else:\n",
        "        i = ctx_start\n",
        "        for start_end_char in offset[ctx_start:]:\n",
        "            start, end = start_end_char\n",
        "            if start == ans_start_char:\n",
        "                start_idx = i\n",
        "            if end == ans_end_char:\n",
        "                end_idx = i\n",
        "                break\n",
        "            i+=1\n",
        "    return start_idx, end_idx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlIIWzUH795v"
      },
      "outputs": [],
      "source": [
        "start_idxs = []\n",
        "end_idxs = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLdDyvHA792o",
        "outputId": "a3ae698e-db71-42f4-d1d5-ecab4bb0df57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([53, 17, 0, 0], [57, 21, 0, 0])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i, offset in enumerate(inputs['offset_mapping']):\n",
        "    sequence_ids = inputs.sequence_ids(i)\n",
        "    ctx_start = sequence_ids.index(1)\n",
        "    ctx_end = len(sequence_ids) - sequence_ids[::-1].index(1)-1\n",
        "    start_idx, end_idx = find_answer_token_idx(\n",
        "        ctx_start,\n",
        "        ctx_end,\n",
        "        ans_start_char,\n",
        "        ans_end_char,\n",
        "        offset\n",
        "    )\n",
        "\n",
        "    start_idxs.append(start_idx)\n",
        "    end_idxs.append(end_idx)\n",
        "\n",
        "start_idxs, end_idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV2gtOIw79zf",
        "outputId": "93acc09c-35bf-482e-a07c-b53f70f780b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In what city and state did Beyonce  grow up? \n",
            " The album, Dangerously in Love  achieved what spot on the Billboard Top 100 chart?\n",
            "Which song did Beyonce sing at the first couple's inaugural ball? \n",
            "What event did Beyoncé perform at one month after Obama's inauguration? \n",
            "Where was the album released? \n",
            "What movie influenced Beyonce towards empowerment themes? \n"
          ]
        }
      ],
      "source": [
        "for q in raw_datasets[\"train\"][\"question\"][:1000]:\n",
        "    if q.strip() != q:\n",
        "        print(q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nngu_OOs79xs"
      },
      "outputs": [],
      "source": [
        "max_length = 384\n",
        "stride = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-_ofZ1BAqT1"
      },
      "outputs": [],
      "source": [
        "def tokenize_fn_train(batch):\n",
        "    questions = [q.strip() for q in batch[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        batch[\"context\"],\n",
        "        max_length=max_length,\n",
        "        truncation=\"only_second\",\n",
        "        stride=stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    orig_sample_idxs = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "    answers = batch[\"answers\"]\n",
        "    start_idxs, end_idxs = [], []\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        sample_idx = orig_sample_idxs[i]\n",
        "        answer = answers[sample_idx]\n",
        "        ans_start_char = answer[\"answer_start\"][0]\n",
        "        ans_end_char = ans_start_char + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "        ctx_start = sequence_ids.index(1)\n",
        "        ctx_end = len(sequence_ids) - sequence_ids[::-1].index(1)-1\n",
        "        start_idx, end_idx = find_answer_token_idx(\n",
        "            ctx_start,\n",
        "            ctx_end,\n",
        "            ans_start_char,\n",
        "            ans_end_char,\n",
        "            offset\n",
        "        )\n",
        "        start_idxs.append(start_idx)\n",
        "        end_idxs.append(end_idx)\n",
        "    inputs[\"start_positions\"] = start_idxs\n",
        "    inputs[\"end_positions\"] = end_idxs\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mPkjv3RDg5c",
        "outputId": "89848948-e79b-4a6a-c6a2-6097ec820944"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4379, 4475)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset = raw_datasets[\"train\"].map(\n",
        "    tokenize_fn_train,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"train\"].column_names,\n",
        ")\n",
        "len(raw_datasets[\"train\"]), len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zikbkdvDEEP_",
        "outputId": "da1de629-4e3b-4880-84dc-70db4439dc7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '56be4db0acb8001400a502ec',\n",
              " 'title': 'Super_Bowl_50',\n",
              " 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
              " 'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
              " 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
              "  'answer_start': [177, 177, 177]}}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_datasets[\"validation\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9mPDz5iE6Xa"
      },
      "outputs": [],
      "source": [
        "def tokenize_fn_validation(batch):\n",
        "    questions = [q.strip() for q in batch[\"question\"]]\n",
        "    inputs=tokenizer(\n",
        "        questions,\n",
        "        batch[\"context\"],\n",
        "        max_length=max_length,\n",
        "        truncation=\"only_second\",\n",
        "        stride=stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    orig_sample_idxs = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "    sample_ids = []\n",
        "    for i in range(len(inputs[\"input_ids\"])):\n",
        "        sample_idx = orig_sample_idxs[i]\n",
        "        sample_ids.append(batch[\"id\"][sample_idx])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "        offset = inputs[\"offset_mapping\"][i]\n",
        "        inputs[\"offset_mapping\"][i] = [\n",
        "            x if sequence_ids[j] == 1 else None for j, x in enumerate(offset)\n",
        "        ]\n",
        "    inputs[\"sample_id\"] = sample_ids\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "32e03af1cb5c462da960c9dbf134ac45",
            "d7de8fafa00a4a089e53fd7b5a6f55c6",
            "1360369214c74a7baea8da96d43b6c69",
            "6862226c9a4041b2982b3a194aae061e",
            "59d00a1d925f4a2f8fb87b0da52bb14d",
            "8d7baf931efa4693a863d87235e02f06",
            "61893744686d4fcf8421505c57bbe4a2",
            "6c864df971974591a13e5e54e05e2d03",
            "0443864858964330b20f25bc5429d090",
            "425ca30c8bf54168b5f52d3a333ca462",
            "ec457715882849a288dabb1524021a51"
          ]
        },
        "id": "LmShitl6G4vD",
        "outputId": "c04509af-bf4d-4c29-87cc-d3dc5a773fa8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32e03af1cb5c462da960c9dbf134ac45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4379 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(4379, 4534)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_dataset = raw_datasets[\"validation\"].map(\n",
        "    tokenize_fn_validation,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets [\"validation\"].column_names\n",
        ")\n",
        "len(raw_datasets[\"validation\"]), len(validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mkh1LNOUHz0_",
        "outputId": "3eab9861-81cd-490d-a264-e8eaa78e737b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-32-af5c830b2dcb>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"squad\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/squad/squad.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric(\"squad\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9cETO-rIXne",
        "outputId": "242841f7-9519-4d0d-dff4-58f16a7de55b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'exact_match': 50.0, 'f1': 50.0}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_answers = [\n",
        "    {\"id\": '1', \"prediction_text\": \"This is the predicted answer.\"},\n",
        "    {\"id\": '2', \"prediction_text\": \"Another prediction here.\"},\n",
        "]\n",
        "\n",
        "true_answers = [\n",
        "    {\"id\": '1', \"answers\": {\"text\": [\"This is the predicted answer.\"], \"answer_start\": [0]}},\n",
        "    {\"id\": '2', \"answers\": {\"text\": [\"The real answer is this one.\"], \"answer_start\": [15]}},\n",
        "]\n",
        "\n",
        "metric.compute(predictions=predicted_answers, references=true_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j58v97BJKjH"
      },
      "outputs": [],
      "source": [
        "small_validation_dataset = raw_datasets[\"validation\"].select(range(100))\n",
        "trained_checkpoint = \"distilbert-base-cased-distilled-squad\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psqzspoeKlmA"
      },
      "outputs": [],
      "source": [
        "tokenizer2 = AutoTokenizer.from_pretrained(trained_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GOk7zkTKxGJ"
      },
      "outputs": [],
      "source": [
        "old_tokenizer = tokenizer\n",
        "tokenizer = tokenizer2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hRH0HChK_0p"
      },
      "outputs": [],
      "source": [
        "small_validation_processed = small_validation_dataset.map(\n",
        "    tokenize_fn_validation,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"validation\"].column_names\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnYKwqvTLbv1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForQuestionAnswering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BlNHWAFLoYw"
      },
      "outputs": [],
      "source": [
        "small_model_inputs = small_validation_processed.remove_columns(\n",
        "    [\"sample_id\", \"offset_mapping\"]\n",
        ")\n",
        "small_model_inputs.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MrrI8yEMBhY"
      },
      "outputs": [],
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXFnfCHUMM8l"
      },
      "outputs": [],
      "source": [
        "small_model_inputs_gpu = {\n",
        "    k : small_model_inputs[k].to(device) for k in small_model_inputs.column_names\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MkysRSSMiNA"
      },
      "outputs": [],
      "source": [
        "trained_model = AutoModelForQuestionAnswering.from_pretrained(\n",
        "    trained_checkpoint\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyaBVN7LMvil"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  outputs = trained_model(**small_model_inputs_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XikwfmTaM_Zt",
        "outputId": "b3094626-20e7-4580-db30-c7013a1c731b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ -2.2607,  -5.1783,  -5.2709,  ...,  -9.5243,  -9.5183,  -9.5288],\n",
              "        [ -2.5961,  -5.5482,  -5.5313,  ...,  -9.9598,  -9.9533,  -9.9860],\n",
              "        [ -3.7127,  -7.1848,  -8.5388,  ..., -11.6557, -11.6571, -11.6505],\n",
              "        ...,\n",
              "        [ -2.0260,  -4.4167,  -4.4980,  ...,  -8.1479,  -8.1530,  -8.1760],\n",
              "        [ -4.1553,  -5.8304,  -7.1643,  ..., -10.5255, -10.5251, -10.4890],\n",
              "        [ -3.2000,  -5.8162,  -6.7249,  ...,  -9.4935,  -9.5038,  -9.4871]],\n",
              "       device='cuda:0'), end_logits=tensor([[ -0.7353,  -4.9236,  -5.1048,  ...,  -8.8734,  -8.8916,  -8.8550],\n",
              "        [ -1.3056,  -5.3870,  -5.4945,  ...,  -9.4895,  -9.5039,  -9.4958],\n",
              "        [ -2.7649,  -7.2201,  -9.0916,  ..., -11.3106, -11.3414, -11.2702],\n",
              "        ...,\n",
              "        [ -0.0768,  -4.8210,  -4.4374,  ...,  -8.0483,  -8.0502,  -7.9903],\n",
              "        [ -2.7347,  -5.3650,  -7.2549,  ..., -10.0498, -10.0661,  -9.9886],\n",
              "        [ -1.0991,  -4.2569,  -6.1267,  ...,  -8.6882,  -8.6889,  -8.6272]],\n",
              "       device='cuda:0'), hidden_states=None, attentions=None)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywwM-pxsNEED"
      },
      "outputs": [],
      "source": [
        "start_logits = outputs.start_logits.cpu().numpy()\n",
        "end_logits = outputs.end_logits.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GIyWGzrNW9e",
        "outputId": "401fd559-b81f-4868-d169-c850a0296d04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['56be4db0acb8001400a502ec',\n",
              " '56be4db0acb8001400a502ed',\n",
              " '56be4db0acb8001400a502ee',\n",
              " '56be4db0acb8001400a502ef',\n",
              " '56be4db0acb8001400a502f0']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "small_validation_processed[\"sample_id\"][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5wh6HxfNjKB"
      },
      "outputs": [],
      "source": [
        "sample_id2idxs = {}\n",
        "for i, id_ in enumerate(small_validation_processed['sample_id']):\n",
        "    if id_ not in sample_id2idxs:\n",
        "        sample_id2idxs[id_] = [i]\n",
        "    else:\n",
        "        print(\"here\")\n",
        "        sample_id2idxs[id_].append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmKyUVO3a3T5",
        "outputId": "51df3527-1587-45e9-fdda-8c0aab05285e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'56be4db0acb8001400a502ec': [0],\n",
              " '56be4db0acb8001400a502ed': [1],\n",
              " '56be4db0acb8001400a502ee': [2],\n",
              " '56be4db0acb8001400a502ef': [3],\n",
              " '56be4db0acb8001400a502f0': [4],\n",
              " '56be8e613aeaaa14008c90d1': [5],\n",
              " '56be8e613aeaaa14008c90d2': [6],\n",
              " '56be8e613aeaaa14008c90d3': [7],\n",
              " '56bea9923aeaaa14008c91b9': [8],\n",
              " '56bea9923aeaaa14008c91ba': [9],\n",
              " '56bea9923aeaaa14008c91bb': [10],\n",
              " '56beace93aeaaa14008c91df': [11],\n",
              " '56beace93aeaaa14008c91e0': [12],\n",
              " '56beace93aeaaa14008c91e1': [13],\n",
              " '56beace93aeaaa14008c91e2': [14],\n",
              " '56beace93aeaaa14008c91e3': [15],\n",
              " '56bf10f43aeaaa14008c94fd': [16],\n",
              " '56bf10f43aeaaa14008c94fe': [17],\n",
              " '56bf10f43aeaaa14008c94ff': [18],\n",
              " '56bf10f43aeaaa14008c9500': [19],\n",
              " '56bf10f43aeaaa14008c9501': [20],\n",
              " '56d20362e7d4791d009025e8': [21],\n",
              " '56d20362e7d4791d009025e9': [22],\n",
              " '56d20362e7d4791d009025ea': [23],\n",
              " '56d20362e7d4791d009025eb': [24],\n",
              " '56d600e31c85041400946eae': [25],\n",
              " '56d600e31c85041400946eb0': [26],\n",
              " '56d600e31c85041400946eb1': [27],\n",
              " '56d9895ddc89441400fdb50e': [28],\n",
              " '56d9895ddc89441400fdb510': [29],\n",
              " '56be4e1facb8001400a502f6': [30],\n",
              " '56be4e1facb8001400a502f9': [31],\n",
              " '56be4e1facb8001400a502fa': [32],\n",
              " '56beaa4a3aeaaa14008c91c2': [33],\n",
              " '56beaa4a3aeaaa14008c91c3': [34],\n",
              " '56bead5a3aeaaa14008c91e9': [35],\n",
              " '56bead5a3aeaaa14008c91ea': [36],\n",
              " '56bead5a3aeaaa14008c91eb': [37],\n",
              " '56bead5a3aeaaa14008c91ec': [38],\n",
              " '56bead5a3aeaaa14008c91ed': [39],\n",
              " '56bf159b3aeaaa14008c9507': [40],\n",
              " '56bf159b3aeaaa14008c9508': [41],\n",
              " '56bf159b3aeaaa14008c9509': [42],\n",
              " '56bf159b3aeaaa14008c950a': [43],\n",
              " '56bf159b3aeaaa14008c950b': [44],\n",
              " '56d2045de7d4791d009025f3': [45],\n",
              " '56d2045de7d4791d009025f4': [46],\n",
              " '56d2045de7d4791d009025f5': [47],\n",
              " '56d2045de7d4791d009025f6': [48],\n",
              " '56d6017d1c85041400946ebe': [49],\n",
              " '56d6017d1c85041400946ec1': [50],\n",
              " '56d6017d1c85041400946ec2': [51],\n",
              " '56d98a59dc89441400fdb52a': [52],\n",
              " '56d98a59dc89441400fdb52b': [53],\n",
              " '56d98a59dc89441400fdb52e': [54],\n",
              " '56be4eafacb8001400a50302': [55],\n",
              " '56be4eafacb8001400a50303': [56],\n",
              " '56be4eafacb8001400a50304': [57],\n",
              " '56beab833aeaaa14008c91d2': [58],\n",
              " '56beab833aeaaa14008c91d3': [59],\n",
              " '56beab833aeaaa14008c91d4': [60],\n",
              " '56beae423aeaaa14008c91f4': [61],\n",
              " '56beae423aeaaa14008c91f5': [62],\n",
              " '56beae423aeaaa14008c91f6': [63],\n",
              " '56beae423aeaaa14008c91f7': [64],\n",
              " '56bf17653aeaaa14008c9511': [65],\n",
              " '56bf17653aeaaa14008c9513': [66],\n",
              " '56bf17653aeaaa14008c9514': [67],\n",
              " '56bf17653aeaaa14008c9515': [68],\n",
              " '56d204ade7d4791d00902603': [69],\n",
              " '56d204ade7d4791d00902604': [70],\n",
              " '56d601e41c85041400946ece': [71],\n",
              " '56d601e41c85041400946ecf': [72],\n",
              " '56d601e41c85041400946ed0': [73],\n",
              " '56d601e41c85041400946ed1': [74],\n",
              " '56d601e41c85041400946ed2': [75],\n",
              " '56d98b33dc89441400fdb53b': [76],\n",
              " '56d98b33dc89441400fdb53c': [77],\n",
              " '56d98b33dc89441400fdb53d': [78],\n",
              " '56d98b33dc89441400fdb53e': [79],\n",
              " '56be5333acb8001400a5030a': [80],\n",
              " '56be5333acb8001400a5030b': [81],\n",
              " '56be5333acb8001400a5030c': [82],\n",
              " '56be5333acb8001400a5030d': [83],\n",
              " '56be5333acb8001400a5030e': [84],\n",
              " '56beaf5e3aeaaa14008c91fd': [85],\n",
              " '56beaf5e3aeaaa14008c91fe': [86],\n",
              " '56beaf5e3aeaaa14008c91ff': [87],\n",
              " '56beaf5e3aeaaa14008c9200': [88],\n",
              " '56beaf5e3aeaaa14008c9201': [89],\n",
              " '56bf1ae93aeaaa14008c951b': [90],\n",
              " '56bf1ae93aeaaa14008c951c': [91],\n",
              " '56bf1ae93aeaaa14008c951e': [92],\n",
              " '56bf1ae93aeaaa14008c951f': [93],\n",
              " '56d2051ce7d4791d00902608': [94],\n",
              " '56d2051ce7d4791d00902609': [95],\n",
              " '56d2051ce7d4791d0090260a': [96],\n",
              " '56d2051ce7d4791d0090260b': [97],\n",
              " '56d602631c85041400946ed8': [98],\n",
              " '56d602631c85041400946eda': [99]}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_id2idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXaXn690OLXP",
        "outputId": "aae0c080-06ed-44d7-f6f9-972d6e103e1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((100, 384), (100, 384))"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "start_logits.shape, end_logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PajYvJuOQ9Y",
        "outputId": "ca8a6058-4368-4833-99ed-6c2f0e7c402d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 46,  57,  47,  38,  39,  58,  50,  43,  45,  54,  56,  49,  13,\n",
              "        42,  40,  35,  27,  31,  48,  41,  53,  44,  37,  59,  78,  15,\n",
              "         0,  52,  24,  65,  81,  70,  18,  51,  55,  26,  69,  29,  28,\n",
              "        75,  61,  64,  23,  36,  32,  11, 101,  62,  66,  34,  95,  30,\n",
              "        63,  21,  19,  20,  17,  14,  22,  33,  68,  87, 171,  12,  76,\n",
              "        71,  73,  92, 110,  84, 151,   1,  74,   2,   6,  16,  80,  79,\n",
              "       105,  98,  10,  96, 136, 169, 106, 100,  93, 165,  67, 109,   8,\n",
              "        90,   3, 115,  60,   5,  97,   7, 103, 102,  86,  72, 111,  89,\n",
              "       108,   4,  88,  25, 132,  77, 123, 150, 124, 153,  83, 118,  82,\n",
              "        85, 107, 114, 143, 164, 137, 130, 166, 159, 131,  91,   9, 144,\n",
              "       139, 160,  94, 141, 128, 112, 134, 152, 170, 154, 117, 127, 104,\n",
              "       140, 157, 155, 133, 145, 119, 162, 138, 135, 156, 167, 168, 126,\n",
              "       148, 163, 161, 116,  99, 120, 142, 158, 125, 146, 113, 121, 147,\n",
              "       149, 129, 122, 311, 312, 304, 309, 313, 310, 300, 307, 316, 308,\n",
              "       314, 306, 317, 320, 319, 321, 291, 318, 301, 305, 287, 270, 315,\n",
              "       295, 289, 294, 251, 333, 303, 269, 299, 274, 265, 298, 176, 175,\n",
              "       338, 292, 323, 322, 290, 252, 296, 229, 177, 302, 297, 186, 245,\n",
              "       250, 283, 174, 256, 337, 266, 190, 293, 286, 264, 288, 331, 327,\n",
              "       234, 237, 227, 284, 255, 326, 276, 272, 233, 346, 191, 230, 218,\n",
              "       232, 179, 285, 273, 173, 187, 239, 332, 172, 267, 329, 238, 253,\n",
              "       334, 214, 192, 325, 278, 350, 259, 281, 268, 185, 254, 271, 279,\n",
              "       342, 345, 343, 181, 335, 183, 189, 260, 341, 275, 178, 228, 210,\n",
              "       324, 277, 212, 348, 209, 336, 261, 240, 249, 246, 194, 257, 182,\n",
              "       377, 258, 196, 195, 248, 188, 339, 197, 213, 378, 263, 208, 201,\n",
              "       205, 200, 225, 211, 282, 236, 204, 347, 203, 262, 223, 193, 330,\n",
              "       199, 202, 349, 184, 180, 351, 340, 226, 224, 243, 217, 372, 244,\n",
              "       241, 207, 235, 344, 215, 367, 247, 368, 382, 352, 379, 353, 221,\n",
              "       376, 231, 380, 220, 371, 366, 242, 219, 381, 206, 375, 369, 216,\n",
              "       198, 355, 383, 280, 328, 222, 358, 373, 357, 363, 356, 374, 354,\n",
              "       359, 365, 370, 364, 362, 361, 360])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(-start_logits[0]).argsort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNMT8GyfOeMW",
        "outputId": "4540b70e-c65d-4ca7-bc1e-9098695242dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([10.694445  ,  9.803685  ,  4.459973  ,  4.400487  ,  2.9437785 ,\n",
              "        2.7017367 ,  2.0126448 ,  1.5780739 ,  0.52237445,  0.02073721,\n",
              "       -0.02802688, -0.04971648, -0.38573122, -0.6945363 , -0.7979508 ,\n",
              "       -0.86780477, -0.87220925, -1.3516886 , -1.3703715 , -1.3878827 ,\n",
              "       -1.5135094 , -1.7355472 , -1.8827027 , -1.8932863 , -1.9078972 ,\n",
              "       -1.9304978 , -2.2607322 , -2.2983866 , -2.3069332 , -2.5027428 ,\n",
              "       -2.510063  , -2.530842  , -2.5399983 , -2.6718144 , -2.732354  ,\n",
              "       -2.7710216 , -2.7713673 , -2.9521358 , -3.0604653 , -3.1706066 ,\n",
              "       -3.204542  , -3.569336  , -3.5798059 , -3.6668851 , -3.7250628 ,\n",
              "       -3.7498565 , -3.7632205 , -3.996814  , -4.0113316 , -4.0688004 ,\n",
              "       -4.0944853 , -4.195475  , -4.2383103 , -4.3323617 , -4.352419  ,\n",
              "       -4.3879614 , -4.38861   , -4.396615  , -4.6790547 , -4.7030315 ,\n",
              "       -4.7757587 , -4.7778134 , -4.788218  , -4.7882495 , -4.8221273 ,\n",
              "       -4.872539  , -4.8849363 , -4.8981495 , -5.072096  , -5.10788   ,\n",
              "       -5.1486406 , -5.178329  , -5.191211  , -5.2709002 , -5.3146424 ,\n",
              "       -5.3770766 , -5.5316567 , -5.571128  , -5.6498227 , -5.661312  ,\n",
              "       -5.6778703 , -5.6986046 , -5.751567  , -5.842644  , -5.8621545 ,\n",
              "       -5.9076943 , -5.9093847 , -5.9444485 , -5.996893  , -6.005829  ,\n",
              "       -6.047037  , -6.0640035 , -6.085876  , -6.1005545 , -6.224175  ,\n",
              "       -6.2670965 , -6.2752924 , -6.3032937 , -6.31342   , -6.328805  ,\n",
              "       -6.3306923 , -6.4014874 , -6.4204855 , -6.4361095 , -6.437409  ,\n",
              "       -6.450712  , -6.53143   , -6.5530505 , -6.563022  , -6.668796  ,\n",
              "       -6.7266903 , -6.742629  , -6.744297  , -6.745856  , -6.8108754 ,\n",
              "       -6.921636  , -6.949301  , -6.990772  , -6.9987435 , -7.162264  ,\n",
              "       -7.167353  , -7.1756635 , -7.180565  , -7.1967816 , -7.243593  ,\n",
              "       -7.2733436 , -7.2769523 , -7.3002205 , -7.300931  , -7.3218613 ,\n",
              "       -7.3976803 , -7.4330378 , -7.524845  , -7.5272303 , -7.5322757 ,\n",
              "       -7.573714  , -7.5982127 , -7.658098  , -7.6597095 , -7.7155743 ,\n",
              "       -7.718405  , -7.7400193 , -7.7546544 , -7.885649  , -7.8937654 ,\n",
              "       -7.894368  , -7.938035  , -7.958206  , -8.037518  , -8.059216  ,\n",
              "       -8.063911  , -8.104637  , -8.117334  , -8.138481  , -8.145774  ,\n",
              "       -8.221222  , -8.274247  , -8.292227  , -8.293207  , -8.316828  ,\n",
              "       -8.317498  , -8.334003  , -8.46651   , -8.500584  , -8.502033  ,\n",
              "       -8.591039  , -8.612478  , -8.621495  , -8.6252165 , -8.62546   ,\n",
              "       -8.814265  , -9.039057  , -9.421061  , -9.434792  , -9.4414625 ,\n",
              "       -9.444372  , -9.449848  , -9.450177  , -9.450438  , -9.451044  ,\n",
              "       -9.452064  , -9.452417  , -9.452519  , -9.454133  , -9.456526  ,\n",
              "       -9.458107  , -9.458341  , -9.458446  , -9.458754  , -9.460873  ,\n",
              "       -9.462076  , -9.462511  , -9.462944  , -9.463792  , -9.463905  ,\n",
              "       -9.465524  , -9.466457  , -9.468561  , -9.468853  , -9.468954  ,\n",
              "       -9.469498  , -9.469519  , -9.470058  , -9.470969  , -9.471138  ,\n",
              "       -9.471284  , -9.47136   , -9.471792  , -9.471888  , -9.472047  ,\n",
              "       -9.472694  , -9.472961  , -9.47371   , -9.475201  , -9.4766035 ,\n",
              "       -9.476761  , -9.476779  , -9.4774065 , -9.478309  , -9.478877  ,\n",
              "       -9.479751  , -9.479915  , -9.480066  , -9.480646  , -9.481189  ,\n",
              "       -9.481474  , -9.48152   , -9.481533  , -9.481612  , -9.48179   ,\n",
              "       -9.482165  , -9.482849  , -9.483409  , -9.484575  , -9.484707  ,\n",
              "       -9.484897  , -9.485176  , -9.485302  , -9.485718  , -9.48596   ,\n",
              "       -9.486807  , -9.486976  , -9.487629  , -9.487733  , -9.487908  ,\n",
              "       -9.487989  , -9.488306  , -9.488396  , -9.48859   , -9.488794  ,\n",
              "       -9.488956  , -9.489108  , -9.489487  , -9.489674  , -9.490006  ,\n",
              "       -9.490808  , -9.490833  , -9.490876  , -9.4909    , -9.491136  ,\n",
              "       -9.491258  , -9.49171   , -9.49203   , -9.492166  , -9.492534  ,\n",
              "       -9.492819  , -9.493566  , -9.493645  , -9.493655  , -9.494009  ,\n",
              "       -9.494032  , -9.494384  , -9.495204  , -9.495423  , -9.496533  ,\n",
              "       -9.496601  , -9.497125  , -9.49753   , -9.4975605 , -9.49757   ,\n",
              "       -9.497612  , -9.497622  , -9.498015  , -9.498126  , -9.498631  ,\n",
              "       -9.498655  , -9.498768  , -9.499587  , -9.500014  , -9.500341  ,\n",
              "       -9.50042   , -9.500582  , -9.5009775 , -9.500998  , -9.50117   ,\n",
              "       -9.501225  , -9.501287  , -9.501437  , -9.501509  , -9.501883  ,\n",
              "       -9.502013  , -9.502524  , -9.502687  , -9.503571  , -9.503639  ,\n",
              "       -9.503665  , -9.504168  , -9.504552  , -9.505051  , -9.505538  ,\n",
              "       -9.506176  , -9.506638  , -9.5066805 , -9.506758  , -9.506831  ,\n",
              "       -9.507124  , -9.507556  , -9.5077305 , -9.507984  , -9.508048  ,\n",
              "       -9.508078  , -9.508736  , -9.508773  , -9.50886   , -9.509268  ,\n",
              "       -9.509509  , -9.509532  , -9.510821  , -9.511501  , -9.512038  ,\n",
              "       -9.512431  , -9.512821  , -9.513132  , -9.513145  , -9.513196  ,\n",
              "       -9.513245  , -9.513383  , -9.514933  , -9.5154295 , -9.515567  ,\n",
              "       -9.516188  , -9.516245  , -9.516346  , -9.51638   , -9.516658  ,\n",
              "       -9.517014  , -9.518301  , -9.518472  , -9.518793  , -9.519091  ,\n",
              "       -9.520803  , -9.521007  , -9.521188  , -9.52123   , -9.522545  ,\n",
              "       -9.522749  , -9.522892  , -9.523227  , -9.523898  , -9.524339  ,\n",
              "       -9.525378  , -9.526041  , -9.52703   , -9.528465  , -9.528533  ,\n",
              "       -9.528625  , -9.528757  , -9.529464  , -9.529711  , -9.531369  ,\n",
              "       -9.532368  , -9.532749  , -9.535536  , -9.536652  , -9.537719  ,\n",
              "       -9.538665  , -9.539045  , -9.539342  , -9.540272  , -9.541709  ,\n",
              "       -9.548323  , -9.554484  , -9.557686  , -9.567405  ], dtype=float32)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "start_logits[0][(-start_logits[0]).argsort()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsQ-7nB3On0x"
      },
      "outputs": [],
      "source": [
        "n_largest = 20\n",
        "max_answer_length = 30\n",
        "predicted_answers = []\n",
        "\n",
        "for sample in small_validation_dataset:\n",
        "    sample_id = sample['id']\n",
        "    context = sample['context']\n",
        "    best_score = float('-inf')\n",
        "    best_answer = None\n",
        "    for idx in sample_id2idxs[sample_id]:\n",
        "        start_logit = start_logits[idx]\n",
        "        end_logit = end_logits[idx]\n",
        "        offsets = small_validation_processed[idx]['offset_mapping']\n",
        "        start_indices = (-start_logit).argsort()\n",
        "        end_indices = (-end_logit).argsort()\n",
        "        for start_idx in start_indices[:n_largest]:\n",
        "            for end_idx in end_indices[:n_largest]:\n",
        "                if offsets[start_idx] is None or offsets[end_idx] is None:\n",
        "                    continue\n",
        "                if end_idx < start_idx:\n",
        "                    continue\n",
        "                if end_idx - start_idx +1 > max_answer_length:\n",
        "                    continue\n",
        "                score = start_logit[start_idx] + end_logit[end_idx]\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    first_ch = offsets[start_idx][0]\n",
        "                    last_ch = offsets[end_idx][1]\n",
        "                    best_answer = context[first_ch:last_ch]\n",
        "    predicted_answers.append({'id' : sample_id, 'prediction_text':best_answer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kb6JujGaG6j"
      },
      "outputs": [],
      "source": [
        "true_answers = [\n",
        "    {'id':x['id'], 'answers': x['answers']} for x in small_validation_dataset\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRMctsZZcB3s",
        "outputId": "01a2afc5-c411-4e63-d842-d49b6b9d452a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'exact_match': 83.0, 'f1': 88.25000000000004}"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric.compute(predictions=predicted_answers, references=true_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj4fDOadcSkG"
      },
      "outputs": [],
      "source": [
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "def compute_metrics(start_logits, end_logits, processed_dataset, orig_dataset):\n",
        "    sample_id2idxs = {}\n",
        "    for i, id_ in enumerate(processed_dataset[\"sample_id\"]):\n",
        "        if id_ not in sample_id2idxs:\n",
        "            sample_id2idxs[id_] = [i]\n",
        "        else:\n",
        "            sample_id2idxs[id_].append(i)\n",
        "    predicted_answers = []\n",
        "    for sample in tqdm(orig_dataset):\n",
        "        sample_id = sample[\"id\"]\n",
        "        context = sample[\"context\"]\n",
        "        best_score = float(\"-inf\")\n",
        "        best_answer = None\n",
        "        for idx in sample_id2idxs[sample_id]:\n",
        "            start_logit = start_logits[idx]\n",
        "            end_logit = end_logits[idx]\n",
        "            offsets = processed_dataset[idx][\"offset_mapping\"]\n",
        "            start_indices = (-start_logit).argsort()\n",
        "            end_indices = (-end_logit).argsort()\n",
        "            for start_idx in start_indices[:n_largest]:\n",
        "                for end_idx in end_indices[:n_largest]:\n",
        "                    if offsets[start_idx] is None or offsets[end_idx] is None:\n",
        "                        continue\n",
        "                    if end_idx < start_idx:\n",
        "                        continue\n",
        "                    if end_idx - start_idx + 1 > max_answer_length:\n",
        "                        continue\n",
        "                    score = start_logit[start_idx] + end_logit[end_idx]\n",
        "                    if score > best_score:\n",
        "                        best_score = score\n",
        "                        first_ch = offsets[start_idx][0]\n",
        "                        last_ch = offsets[end_idx][1]\n",
        "                        best_answer = context[first_ch:last_ch]\n",
        "        predicted_answers.append({\"id\" : sample_id, \"prediction_text\": best_answer})\n",
        "    true_answers = [\n",
        "        {\"id\" : x[\"id\"], \"answers\" : x[\"answers\"]} for x in orig_dataset\n",
        "    ]\n",
        "    return metric.compute(predictions=predicted_answers, references=true_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "d1cb5602ccf44371a3723f6aef439e04",
            "6ff442e5e1d347acb17a27cfd50f61bc",
            "84bb303114a04554953f52ae39ea96d2",
            "54e082308367456c9364a8dcc73ad1cf",
            "81815a4615ab4517b438fb505254116d",
            "3bf1550f09d64fd5ad08db0dbb23f6ad",
            "7dbcb812da584a49bde0d0302143e7a8",
            "358585b26bc14d02a7730b5b6521a0e5",
            "e41ea3e855a640469f30436da7afda47",
            "cac3e57973fe4502b657306134a6af7d",
            "87134d80de0e4e5586dc7fa1154948d5"
          ]
        },
        "id": "Co7xe9zr-hsI",
        "outputId": "042e74e0-b40a-45a2-a6d4-b7d8777fa628"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1cb5602ccf44371a3723f6aef439e04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'exact_match': 83.0, 'f1': 88.25000000000004}"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_metrics(\n",
        "    start_logits,\n",
        "    end_logits,\n",
        "    small_validation_processed,\n",
        "    small_validation_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pWoGeZ_C_1N",
        "outputId": "579a426a-5350-458f-e832-69527dd24acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VUbmCS1ETEW",
        "outputId": "3d6a1277-1d64-45b1-ee78-4dcafbf7a50c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sCmS6MIAOC24",
        "outputId": "66de2156-bd3d-4575-e0ed-4600930f03a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: transformers 4.41.1\n",
            "Uninstalling transformers-4.41.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/transformers-cli\n",
            "    /usr/local/lib/python3.10/dist-packages/transformers-4.41.1.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/transformers/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled transformers-4.41.1\n",
            "Found existing installation: accelerate 0.30.1\n",
            "Uninstalling accelerate-0.30.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/accelerate\n",
            "    /usr/local/bin/accelerate-config\n",
            "    /usr/local/bin/accelerate-estimate-memory\n",
            "    /usr/local/bin/accelerate-launch\n",
            "    /usr/local/lib/python3.10/dist-packages/accelerate-0.30.1.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/accelerate/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled accelerate-0.30.1\n",
            "Collecting transformers[torch]\n",
            "  Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Using cached accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.40)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: transformers, accelerate\n",
            "Successfully installed accelerate-0.30.1 transformers-4.41.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "5277eb50e51c48b6bf0f62c6ebdfee58",
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install accelerate>=0.21.0\n",
        "!pip uninstall transformers accelerate\n",
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtuoqYZO_Bgo",
        "outputId": "81225b28-6ed5-4205-b2ec-39b071f5cfcd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import  TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"finetuned-squad\",\n",
        "    evaluation_strategy = \"no\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vtiaMnqEgQ6"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "sNA31iwhBCrf",
        "outputId": "debaaeb2-22c3-4e89-c564-41ab2fbb4505"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1680' max='1680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1680/1680 03:44, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.356700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.979600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.459200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1680, training_loss=2.1704765592302593, metrics={'train_runtime': 225.1137, 'train_samples_per_second': 59.637, 'train_steps_per_second': 7.463, 'total_flos': 1315513400947200.0, 'train_loss': 2.1704765592302593, 'epoch': 3.0})"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xmO0bkn_DMnd",
        "outputId": "97f0dc3a-ace4-4386-f11c-73bcd8a2f73a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "transformers.trainer_utils.PredictionOutput"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_output = trainer.predict(validation_dataset)\n",
        "type(trainer_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xunTXoiyDaIj"
      },
      "outputs": [],
      "source": [
        "predictions, _, _ = trainer_output\n",
        "start_logits, end_logits = predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qHgkW56DpJ0"
      },
      "outputs": [],
      "source": [
        "compute_metrics(\n",
        "    start_logits,\n",
        "    end_logits,\n",
        "    validation_dataset,\n",
        "    raw_datasets[\"validation\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoNlg3hPIHpx"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"qa_squad_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGiHh9_aIVWZ"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "qa= pipeline(\n",
        "    \"question-answering\",\n",
        "    model=\"qa_squad_model\",\n",
        "    device=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moP5A0IoIxtL"
      },
      "outputs": [],
      "source": [
        "context=\"Today I went to the store to purchase a carton of milk.\",\n",
        "question=\"What did i buy?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRrwjYzqI3FI"
      },
      "outputs": [],
      "source": [
        "qa(context=context, question=question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiLZzg2UL2rT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0443864858964330b20f25bc5429d090": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1360369214c74a7baea8da96d43b6c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c864df971974591a13e5e54e05e2d03",
            "max": 4379,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0443864858964330b20f25bc5429d090",
            "value": 4379
          }
        },
        "32e03af1cb5c462da960c9dbf134ac45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7de8fafa00a4a089e53fd7b5a6f55c6",
              "IPY_MODEL_1360369214c74a7baea8da96d43b6c69",
              "IPY_MODEL_6862226c9a4041b2982b3a194aae061e"
            ],
            "layout": "IPY_MODEL_59d00a1d925f4a2f8fb87b0da52bb14d"
          }
        },
        "358585b26bc14d02a7730b5b6521a0e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bf1550f09d64fd5ad08db0dbb23f6ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "425ca30c8bf54168b5f52d3a333ca462": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54e082308367456c9364a8dcc73ad1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cac3e57973fe4502b657306134a6af7d",
            "placeholder": "​",
            "style": "IPY_MODEL_87134d80de0e4e5586dc7fa1154948d5",
            "value": " 100/100 [00:00&lt;00:00, 188.34it/s]"
          }
        },
        "59d00a1d925f4a2f8fb87b0da52bb14d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61893744686d4fcf8421505c57bbe4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6862226c9a4041b2982b3a194aae061e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_425ca30c8bf54168b5f52d3a333ca462",
            "placeholder": "​",
            "style": "IPY_MODEL_ec457715882849a288dabb1524021a51",
            "value": " 4379/4379 [00:05&lt;00:00, 622.15 examples/s]"
          }
        },
        "6c864df971974591a13e5e54e05e2d03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff442e5e1d347acb17a27cfd50f61bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bf1550f09d64fd5ad08db0dbb23f6ad",
            "placeholder": "​",
            "style": "IPY_MODEL_7dbcb812da584a49bde0d0302143e7a8",
            "value": "100%"
          }
        },
        "7dbcb812da584a49bde0d0302143e7a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81815a4615ab4517b438fb505254116d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84bb303114a04554953f52ae39ea96d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_358585b26bc14d02a7730b5b6521a0e5",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e41ea3e855a640469f30436da7afda47",
            "value": 100
          }
        },
        "87134d80de0e4e5586dc7fa1154948d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d7baf931efa4693a863d87235e02f06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cac3e57973fe4502b657306134a6af7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1cb5602ccf44371a3723f6aef439e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ff442e5e1d347acb17a27cfd50f61bc",
              "IPY_MODEL_84bb303114a04554953f52ae39ea96d2",
              "IPY_MODEL_54e082308367456c9364a8dcc73ad1cf"
            ],
            "layout": "IPY_MODEL_81815a4615ab4517b438fb505254116d"
          }
        },
        "d7de8fafa00a4a089e53fd7b5a6f55c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d7baf931efa4693a863d87235e02f06",
            "placeholder": "​",
            "style": "IPY_MODEL_61893744686d4fcf8421505c57bbe4a2",
            "value": "Map: 100%"
          }
        },
        "e41ea3e855a640469f30436da7afda47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec457715882849a288dabb1524021a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}